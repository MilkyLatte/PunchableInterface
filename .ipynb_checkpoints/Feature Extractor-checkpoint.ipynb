{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import peakutils\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "sensorData = []\n",
    "soundData  = []\n",
    "labels = []\n",
    "\n",
    "punch0 = []\n",
    "punch1 = []\n",
    "punch2 = []\n",
    "punch3 = []\n",
    "punch4 = []\n",
    "\n",
    "\n",
    " \n",
    "with open ('sensors1.csv', 'r') as readFile:\n",
    "    newFileReader = csv.reader(readFile)\n",
    "    for row in readFile:\n",
    "        line = []\n",
    "        for x in row.split(','):\n",
    "            line1 = []\n",
    "            for y in x.split(' '):\n",
    "                try:\n",
    "                    line1.append(float(y))\n",
    "                except Exception:\n",
    "                    pass\n",
    "            if len(line1) == 6:\n",
    "                line.append(line1)\n",
    "        if len(line) == 100:\n",
    "            sensorData.append(line)\n",
    "with open ('sounds1.csv', 'r') as readFile:\n",
    "    newFileReader = csv.reader(readFile)\n",
    "    for row in readFile:\n",
    "        empty = []\n",
    "        for i in row.split(','):\n",
    "            empty.append(float(i))\n",
    "        soundData.append(empty)\n",
    "with open ('labels1.csv', 'r') as readFile:\n",
    "    newFileReader = csv.reader(readFile)\n",
    "    for row in readFile:\n",
    "        labels.append(int(row))\n",
    "\n",
    "for x in range(len(sensorData)):\n",
    "    if x % 5 == 0:\n",
    "        punch0.append(sensorData[x])\n",
    "    if x % 5 == 1:\n",
    "        punch1.append(sensorData[x])\n",
    "    if x % 5 == 2:\n",
    "        punch2.append(sensorData[x])\n",
    "    if x % 5 == 3:\n",
    "        punch3.append(sensorData[x])\n",
    "    if x % 5 == 4:\n",
    "        punch4.append(sensorData[x])\n",
    "soundData  = np.array(soundData)\n",
    "sensorData = np.array(sensorData)\n",
    "labels     = np.array(labels)\n",
    "punch0 = np.array(punch0)\n",
    "punch1 = np.array(punch1)\n",
    "punch2 = np.array(punch2)\n",
    "punch3 = np.array(punch3)\n",
    "punch4 = np.array(punch4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.fftpack import fft, rfft\n",
    "sensorData = np.array(sensorData)\n",
    "\n",
    "def zeroCrossings(x):\n",
    "    zero_crossings = np.where(np.diff(np.sign(x)))[0]\n",
    "    return(len(zero_crossings))\n",
    "    \n",
    "\n",
    "def featureExtraction(x, sound):\n",
    "    features = []\n",
    "    for u in range(6):\n",
    "        features.append(np.mean(x[:100, u]))\n",
    "        features.append(np.max(x[:100, u]))\n",
    "        features.append(np.min(x[:100, u]))\n",
    "        features.append(np.std(x[:100, u]))\n",
    "        features.append(zeroCrossings(x[:100, u]))\n",
    "        features.append(np.var(x[:100, u]))\n",
    "    features.append(np.std(x[:100, :3]))\n",
    "    features.append(np.std(x[:100, 3:]))\n",
    "    a, b, c, d, e, f, g, h, i = topPeaks(sound)\n",
    "    features.append(a)\n",
    "    features.append(b)\n",
    "    features.append(c)\n",
    "    features.append(d)\n",
    "    features.append(e)\n",
    "    features.append(f)\n",
    "    features.append(g)\n",
    "    features.append(h)\n",
    "    features.append(i)\n",
    "    return features\n",
    "\n",
    "def topPeaks(sound):\n",
    "    fourier = abs(rfft(sound))\n",
    "    phase = (np.angle(rfft(sound)))\n",
    "    indices = peakutils.indexes(fourier, thres=0.02/max(fourier), min_dist=0.1)\n",
    "    amplitudes = (fourier[indices])\n",
    "    amplitudes = (np.sort(amplitudes))[len(amplitudes)-3:len(amplitudes)]\n",
    "    a    = fourier.tolist().index(amplitudes[0])\n",
    "    b    = fourier.tolist().index(amplitudes[1])\n",
    "    c    = fourier.tolist().index(amplitudes[2])\n",
    "    d, e, f = amplitudes\n",
    "    g    = phase[a]\n",
    "    h    = phase[b]\n",
    "    i    = phase[c]\n",
    "    return a, b, c, d, e, f, g, h, i\n",
    "\n",
    "topPeaks(soundData[250,0:])\n",
    "# for x in range(len(sensorData)):\n",
    "#     print(x)\n",
    "#     print(featureExtraction(sensorData[x], soundData[x, 0:]))  \n",
    "features = []\n",
    "\n",
    "for x in range(len(sensorData)):\n",
    "     features.append(featureExtraction(sensorData[x], soundData[x, 0:]))\n",
    "\n",
    "features = np.array(features)\n",
    "\n",
    "training = features[100:]\n",
    "test     = features[:100]\n",
    "training_labels = labels[100:]\n",
    "test_labels = labels[:100]\n",
    "\n",
    "\n",
    "\n",
    "def randomize(dataset, labels):\n",
    "    permutation = np.random.permutation(labels.shape[0])\n",
    "    shuffled_dataset = dataset[permutation]\n",
    "    shuffled_labels  = labels[permutation]\n",
    "    return shuffled_dataset, shuffled_labels\n",
    "\n",
    "\n",
    "train_dataset, train_labels = randomize(training, training_labels)\n",
    "test_dataset, test_labels = randomize(test, test_labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpy_17kqgy\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpy_17kqgy', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6421938518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tensorflow.contrib import learn\n",
    "\n",
    "feature_columns = learn.infer_real_valued_columns_from_input(train_dataset)\n",
    "#classifier = learn.LinearClassifier(n_classes = 5, feature_columns=feature_columns)\n",
    "#classifier = learn.DNNClassifier(feature_columns=feature_columns, hidden_units=[10, 20, 10], n_classes=5)\n",
    "#classifier.fit(train_dataset, train_labels, steps=100000)\n",
    "classifier = tf.estimator.LinearClassifier(n_classes=5, feature_columns=feature_columns)\n",
    "\n",
    "# estimator.fit(train_dataset, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-646c3ff1827d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/internship/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    360\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m       \u001b[0mhooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_hooks_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_train_steps_to_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/internship/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_check_hooks_type\u001b[0;34m(hooks)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_hooks_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m   \u001b[0;34m\"\"\"Returns hooks if all are SessionRunHook, raises TypeError otherwise.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m   \u001b[0mhooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSessionRunHook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "\n",
    "def main():\n",
    "  # If the training and test sets aren't stored locally, download them.\n",
    "  if not os.path.exists(IRIS_TRAINING):\n",
    "    raw = urllib.urlopen(IRIS_TRAINING_URL).read()\n",
    "    with open(IRIS_TRAINING, \"w\") as f:\n",
    "      f.write(raw)\n",
    "\n",
    "  if not os.path.exists(IRIS_TEST):\n",
    "    raw = urllib.urlopen(IRIS_TEST_URL).read()\n",
    "    with open(IRIS_TEST, \"w\") as f:\n",
    "      f.write(raw)\n",
    "\n",
    "  # Load datasets.\n",
    "  training_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "      filename=IRIS_TRAINING,\n",
    "      target_dtype=np.int,\n",
    "      features_dtype=np.float32)\n",
    "  test_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "      filename=IRIS_TEST,\n",
    "      target_dtype=np.int,\n",
    "      features_dtype=np.float32)\n",
    "\n",
    "  # Specify that all features have real-value data\n",
    "  feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[4])]\n",
    "\n",
    "  # Build 3 layer DNN with 10, 20, 10 units respectively.\n",
    "  classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns,\n",
    "                                          hidden_units=[10, 20, 10],\n",
    "                                          n_classes=5,\n",
    "                                          model_dir=\"/liveVersion\")\n",
    "  # Define the training inputs\n",
    "  train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": np.array(training_set.data)},\n",
    "      y=np.array(training_set.target),\n",
    "      num_epochs=None,\n",
    "      shuffle=True)\n",
    "\n",
    "  # Train model.\n",
    "  classifier.train(input_fn=train_input_fn, steps=2000)\n",
    "\n",
    "  # Define the test inputs\n",
    "  test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": np.array(test_set.data)},\n",
    "      y=np.array(test_set.target),\n",
    "      num_epochs=1,\n",
    "      shuffle=False)\n",
    "\n",
    "  # Evaluate accuracy.\n",
    "  accuracy_score = classifier.evaluate(input_fn=test_input_fn)[\"accuracy\"]\n",
    "\n",
    "  print(\"\\nTest Accuracy: {0:f}\\n\".format(accuracy_score))\n",
    "\n",
    "  # Classify two new flower samples.\n",
    "  new_samples = np.array(\n",
    "      [[6.4, 3.2, 4.5, 1.5],\n",
    "       [5.8, 3.1, 5.0, 1.7]], dtype=np.float32)\n",
    "  predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": new_samples},\n",
    "      num_epochs=1,\n",
    "      shuffle=False)\n",
    "\n",
    "  predictions = list(classifier.predict(input_fn=predict_input_fn))\n",
    "  predicted_classes = [p[\"classes\"] for p in predictions]\n",
    "\n",
    "  print(\n",
    "      \"New Samples, Class Predictions:    {}\\n\"\n",
    "      .format(predicted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-41832f502b66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/internship/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, input_fn, steps, hooks, checkpoint_path, name)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m       \u001b[0mhooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_hooks_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m       \u001b[0mhooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_eval_steps_to_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m       \u001b[0;31m# Check that model has been trained (if nothing has been set explicitly).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/internship/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_convert_eval_steps_to_hooks\u001b[0;34m(self, steps)\u001b[0m\n\u001b[1;32m    464\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Must specify steps > 0, given: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_StopAfterNEvalsHook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "classifier.evaluate(test_dataset, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_feature_spec_for_parsing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a0b1a25733ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done exporting tf.learn model to \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mexport_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0msave_tf_learn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"linearClassifier\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SummerInternship/liveVersion\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-a0b1a25733ca>\u001b[0m in \u001b[0;36msave_tf_learn_model\u001b[0;34m(estimator, model_name, export_dir, feature_columns)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_tf_learn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mfeature_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_feature_spec_for_parsing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mserving_input_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_fn_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_parsing_serving_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mexport_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_savedmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserving_input_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_feature_spec_for_parsing' is not defined"
     ]
    }
   ],
   "source": [
    "def save_tf_learn_model(estimator, model_name, export_dir, feature_columns, ):\n",
    "    feature_spec = create_feature_spec_for_parsing(feature_columns)\n",
    "    serving_input_fn = input_fn_utils.build_parsing_serving_input_fn(feature_spec)\n",
    "    export_dir = os.path.join(export_dir, model_name)\n",
    "    estimator.export_savedmodel(export_dir, serving_input_fn)\n",
    "    print(\"Done exporting tf.learn model to \" + export_dir + \"!\")\n",
    "\n",
    "save_tf_learn_model(classifier, \"linearClassifier\", \"SummerInternship/liveVersion\", feature_columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
